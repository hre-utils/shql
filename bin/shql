#!/bin/bash
# baSH Query Language
#
# The `shql` script is essentially an ease-of-use wrapper around data_parser.sh
# and query_parser.sh. It sets the appropriate conditions for both to be run,
# and ensures the requisite data is passed between them.
#
# There are design decisions that I made which may be easily modified for a
# different use case. For example, JSON data must be passed in through a file
# path, or stdin. Queries may only be passed through a file path, or as a param
# on the command line.

#──────────────────────────────────( global )───────────────────────────────────
# String buffers to hold the raw text of our input JSON, and the query string.
declare -- JSON_DATA
declare -- QUERY_DATA

#─────────────────────────────────( functions )─────────────────────────────────
function quick_usage {
cat<<EOF 1>&2
usage:
   ${BASH_SOURCE[0]##*/} -q query_string [<file>]
   ${BASH_SOURCE[0]##*/} -f query_file [<file>]

Options:
   -h, --help        Print this message and exit
   -q, --query       Performs QUERY on input JSON
   -f, --query-file  Performs queries from a file on input JSON
EOF

[[ $1 -gt 0 ]] && exit $1
}


function usage {
quick_usage 0

cat<<EOF 1>&2

Query Semantics:
   1. A full query is structured as \`LOCATION '>' METHOD\`.
      a. Multiple queries may be placed on the same line, separated with ';'.
   2. All locations must begin with '/' to indicate the 'root' of the data.
   3. Lists may be indexed with square bracket notation:  "/[0]".
   4. Dicts may be indexed with dot notation:  "/.foo".

Methods:
   Methods act upon the selected location, and are non-recursive unless stated
   otherwise.

   - len()
      Prints the string length, list lenth, or # keys

   - write('filepath.json')
      Recursively writes data

   - print()
      Recursively prints data

   - delete()
      Recursively deletes data

   - append(DATA)
      Adds JSON DATA to the end of a list

   - prepend(DATA)
      Adds JSON DATA to the start of a list

   - insert(INDEX, DATA)
      Inserts JSON DATA into a list or dict at the specified INDEX. If insert
      into a list, shifts upwards prior to inserting.

   - update(DATA)
      Recursively deletes from the LOCATION, then inserts JSON DATA in its place

Examples:
   Read data from a configuration file, update a value, then print to validate:
   $ shql -q '/.foo > update('bar'); / > print()' config.json

   Insert data into the 3rd index of an existing list:
   $ shql -q '/.bar > insert(3, "new list item")' config.json

   Read JSON from stdin, pretty print it back out:
   $ echo '{"this": "that"}' | shql -q '/ > print()'
EOF

exit $1
}

#─────────────────────────────────( argparse )──────────────────────────────────
while [[ $# -gt 0 ]] ; do
   case $1 in
         -h|--help)
            usage 0
            ;;

         -q|--query)
            shift ; __query__="$1" ; shift
            ;;

         -f|--query-file)
            shift ; __query_file__="$1" ; shift
            ;;

         #-o|--options)
         #   shift ; __options__="$1" ;shift
         #   ;;

         --)
            shift
            break
            ;;

         -*)
            __invalid_opt__+=( $1 ) ; shift
            ;;

         *) __positional__+=( $1 ) ; shift
            ;;
   esac
done

# If user passed '--' for file paths that may begin with a dash.
__positional__+=( "$@" )

#────────────────────────────────( validation )─────────────────────────────────
declare -a argument_errors

# Requires either no position arg (read from stdin), or a file name.
if [[ ${#__positional__[@]} -gt 1 ]] ; then
   args=''
   for arg in "${__positional__[@]}" ; do
      args+="${args:+, }${arg}"
   done

   argument_errors+=(
      "Argument Error: Too many positional args[${args}]. Expected <= 1."
   )
fi

# Query: May not have both a query file & query string.
if [[ -n ${__query_file__} && -n ${__query__} ]] ; then
   argument_errors+=(
      'Argument Error: Requires -q OR -f, not both.'
   )
fi

# Query file: must exist
if [[ -n ${__query_file__} && ! -e ${__query_file__} ]] ; then
   argument_errors+=(
      "File Error: File '${__query_file__}' does not exist."
   )
fi

# Print errors.
if [[ ${#argument_errors[@]} -gt 0 ]] ; then
   for err in "${argument_errors[@]}" ; do
      echo "$err" 1>&2
   done
   quick_usage 1
fi

#─────────────────────────────────( load data )─────────────────────────────────
case "${__positional__[0]}" in
   '') JSON_DATA=/dev/stdin ;;                 # If no FILE arg read from stdin
   *)  JSON_DATA="${__positional__[0]}"        # Else read from specified file.
esac

# Input file must exist.
if [[ ! -e "$JSON_DATA" ]] ; then
   echo "File Error: File '$JSON_DATA' does not exist." 1>&2
   exit -1
fi

if [[ -n ${__query__} ]] ; then
   QUERY_DATA="${__query__}"
elif [[ -n ${__query_file__} ]] ; then
   QUERY_DATA=$( cat "${__query_file__}" )
fi

#────────────────────────────────────( go )─────────────────────────────────────
declare -- CACHE_PREFIX="${XDG_CACHE_HOME:-$HOME/.cache}/hre-utils/shql"
mkdir -p "${CACHE_PREFIX}/data"

# TODO;XXX:
# We have a bit of a Catch 22 here. I need the hash to invoke the data parser.
# But I can't get the hash until the data parser actually finishes reading all
# the data.
# I still want `data_parser` and `query_parser` to function as standalone
# utilities, thus I do not want to make any changes to solve specifically this
# problem. For example, using named pipes, or a textfile, or exported variables
# that identify the hash of this input data set.
#
# Ideas:
#  1) Temp file. Write a temp file under ${CACHE_PREFIX}/hash. Written in
#     data_parser.sh after all data has been read by the lexer.
#  2) Named pipe. Similar philosophy, though we'd be able to handle the creation
#     and cleanup solely within this script. The data_parser only needs to cat
#     the hash to the file.
#  3) Move file. Start by placing the file into a staging/ directory. It has
#     no unique name. The parser will `mv` the file in-place, setting its name?
#     Nope. Don't like.
#  4) Environment variables. This is honestly seeming like the best way so far.
#     Exporting a variable is a pretty straightforward operation.
#
# As I think about it more, I think this is just a poor approach. We shouldn't
# be requiring the data_parser to output to a specific file that we're passing
# in as an argument. Defeats the purpose of a dynamically generated hash of the
# input data.
#
# It should only take the file path as an argument, then it begins to parse.
# Once all the data has been read, it can md5sum the string, check it against
# existing hashes. If it doesn't exist, store the $HASH, wait until a successful
# completion of the parse, then write the cache.
#
# With the above approach we'll still need to notify the user of the most
# recent hash. Text file does feel like the best way to do this. Though we'll
# either need to set to an empty string, or delete, at the beginning of each
# new run.
#
declare -- HASH=$( md5sum <<< "$JSON_DATA" | awk '{print $1}' )
declare -- CACHEFILE="${CACHE_PREFIX}/data/$HASH"

declare -- PARENT_DIR=$( cd "$(dirname "$(dirname "${BASH_SOURCE[0]}")")" ; pwd )
bash "$PARENT_DIR/lib/data_parser.sh" "$JSON_DATA" "$CACHEFILE"
bash "$PARENT_DIR/lib/query_parser.sh" "$QUERY_DATA" "$CACHEFILE"
